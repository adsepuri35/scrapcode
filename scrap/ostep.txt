Intro:

Virtualization - OS takes a physical resource (processor, memory, or disk) and transforms into a more general, more powerful, easy-to-use version of itself. This is why we sometimes call the OS a virtual machine.

OS provides APIs for users to call. 

OS also known as resource manager because it determine what devices, resources to allocate to different programs/processes.

Resources - CPU, memory, disk

Virtualizing the CPU - turning a single CPU into a seemingly infinite number of CPUs, allowing multiple programs to be run at once.

Process identifier (PID) - unique per running process

Multiple processes running program at the same time and increment value at the same location. However, each process updates the value independently. Here, OS is virtualizing memory. Each process accesses its own private virtual address space (the OS maps onto the physical memory of the machine).

Thread - function running within the same memory space as other functions, with more than one of them active at a time.

Persistence - during a power shutoff or system crash, we want to make sure that the data persists within the system.

Hard drives + SSD (solid-state drives) are common repositories for long-lived info.

File system - Software that manages the disk. Stores any files the user creates.

assert() ensures something is something. If not, program terminates.

fsync() ensures all data written to the file is flushed to the disk. Without it, data could remain in the OS buffer cache and be lost in a system crash. 

Device driver - code in OS that knows how to deal with a specific device.

For performance reasons, most file systems delay writes for a while.

Design goals - provide high performance and minimize oveheads of the OS (additional resources consumed by OS to perform tasks)

History:
Batch processing - number of jobs set up and then run in the batch by an operator

System call - transfers control into the OS while raising hardware privilege level. User apps run in user mode.

Kernel mode - OS has full access to the hardware of the system. 

Trap - hardware instruction that raises privilege to kernel and OS services the request.

Virtualization

4 - Processes:
Process - running program.
One usually wants to run more than one program at a time.

OS creates an illusion by virtualizing the CPU. Running one process, stopping it, running another...
This is called "time sharing" of the CPU. 
Each process will run more slowly if CPU must be shared.

Space sharing - resource is divided (in space) among those who wish to use it. Ex. Disk space

Context switch - OS stops running one program and starts running another on a given CPU

Policies - algorithms for making some decision with the OS. Ex. Scheduling policy (uses historical info, workload knowledge, performance metrics)

Machine state - what a program can read or update when it is running.
Obvious component of machine state is memory.
Address space - memory that a process can address (read/write to)
Registers - instructions read or update registers so they are integral to process execution
Special registers:
Program counter (instruction pointer or IP) - which instruction of the process will execute next.
Stack pointer and frame pointer manage the stack for function parameters, local variables, return addresses.
Programs also access persistent storage devices. I/0 info might include a list of files the process currently has open.

4.2 Process API
Create - OS must be able to create new processes. Ex. type a command into the shell, the OS is invoked to create a new process to run the program indicated.
Destroy - Users sometimes have the option to kill processes.
Wait - wait for a process to stop running.
Miscellaneous - ex. suspend process and then resume
Status - how long process has run, what state it is in, etc.

4.3 Process creation
OS must load code and any static data (ex. initialized variables) into memory, into the address space of the process. Programs initially reside on disk (SSDs) in an executable format. So OS reads the bytes from disk and places them in memory elsewhere.

Early OS loaded the process all at once before running the program. Modern OSes perform the process lazily (loading pieces of code or data only as needed during program execution).

Just remember the OS must do some work to get the important program bits from disk to memory.

Before running the process, OS must allocate memory for the program's run-time stack (or just stack). C programs use the stack for local variables, function parameters, and return addresses. The OS allocates this memory and gives it to the process. It will fill in the parameters to the main function (argc and argv array).

OS might allocate memory for program's heap. In C, heap used for explicitly requested dynamically-allocated data. Ex. malloc(), free(). Heap needed for data structures like linked-lists, hash tables, trees, etc.  Heap is small initially. Over time, OS could get involved and request more memory to the process.

OS does initialization tasks for I/O. IN UNIX systems, each process by default has three open file descriptros for std input, output, and error. They let programs easily read input from terminal and print output to screen. Will cover in persistence.

Now OS can start running the program at entry point main(). Jumps to main() routine, OS transfers control of the CPU to the newly created process and begins execution.

4.4 Process States
Different states a process can be in:
Running - process runnning on processor (executing instructions)
Ready - process is ready be run but OS has not chosen to run it yet
Blocked - process has performed an operation that makes it not ready to run until some other event takes place. Ex: process initiates I/0 request to a disk, it becomes blocked and some other process can use the processor.

Scheduled - process moved from ready to running
Opposite = descheduled

4.5 Data structures
OS maintains data structures to keep track of relevant info. 
Process lists - keeps track of the state of each process. Should also keep track of blocked processes. When I/O event completes, OS can make sure to wake the correct process and ready it to run it again.

Pieces of info OS tracks about process:
Register context - holds contents of registers for stopped processes. When process stopped, registers saved to memory location. OS can rerun process by restoring registers. (Context switch)

Other possible states:
Initial - when process first created
Final/Zombie - process finished running but not yet cleaned up. This can allow the parent that created the process to examine return code and ensure successful execution. 0 = successful, any other number = otherwise.

When finished the parent can make a final call to wait for the completion of the child and to indicate to the OS that it can clean up relevant data strucutres for the extinct process.

PCB (Process Control Block) - individual structure that stores info about a process.

5 - Interlude: Process API
Process creation in UNIX systems. UNIX creates a new process with 2 system calls: fork() and exec(). wait() can be used by a process wishing to wait for a process it has created to complete.

fork():
Used to create a new process. Odd routine
The process that is create is almost an exact copy of the calling process. So for the OS, looks like 2 copies of the program p1 running, both are about to return from the fork(). The newly created process (child) doesn't start running at main(), it comes to life as if it called fork() itself.
Child receives return code of 0 while parent receives PID of newly created child.

wait():
parent waits for a child process to finish what it has been doing.
wait(NULL) returns the PID of the terminated child.

exec():
Run a program different from the calling program. fork() runs a copy of the same program. exec() is for different.

Separation of fork() and exec() allows shell code to run after fork() but before call to exec()

Shell is a user program. Assume you type a command. Shell figures out where in the file system the executable is, calls fork() to create a new child process to run the command, calls some variant of exec() to run the command and waits for it to complete by calling wait(). 

Output of a process is connected to an in-kernal pipe (queue) and the input of another process is connected to the same pipe. So output of one process used as input for another.

signal():
sys call for process to catch signals. Could suspend execute or run particular piece of code, etc.

Users generally have their own processes which only they can control. Root users have elevated privileges over these processes.

6 - Mechanism: Limited Direct execution
Direct exec protocol:
OS:
create entry for process list
allocate memory for program
load program into memory
set up stack with argc/argv
clear registers
execute call main()
Program:
run main(), execute return from main
OS:
Free memory of process
Remove from process list.

User mode - restricted. Can't issue I/O requests. Contrast = kernel mode
When user processes want to perform elevated operation, they perform a system call (allow kernel to expose key functionalities to user programs ex. accessing file systems, creating/destroying processes). 

Trap table created at boot time by kernel

Sys call num to specify exact system call. User code places the num in a register or in the stack. OS validates it. This is an extra layer of security.

Return from trap instruction to start process execution

Problem #2 - switching between processes
When a program does something illegal (divide by zero), it generates a trap to the OS. OS resurps control of the CPU.

Timer interrupt - timer device raises an interrupt every couple millizeconds. current process haltes, interrupt handler runs. OS regains control of CPU. Does what it wants (starts new process if necessary). Timer turned on during boot. Can be turned on/off later. When interrupt occurs, a decent portion of the state of the process should be saved.

Context switch - OS saves few register values for current process (onto kernel stack). Restore few for soon to be running process.

Each process has its own kernel stack.
Stores function call data, local vars, return addresses, etc.

Reboot is useful because the software is reverted to a known state.

There are user and kernel registers for a given process. During register saves/restores and interrupt, user registers are implicitly saved by hardware using the kernel stack. When OS switches from one process to another, the kernel registers are saved by OS (into memory in the process structure of the process). Kernel stacks are temporary and only valid while the process is currently running.

OS could disable interrupts during interrupt processing. Locking mechanisms to protect interal data structures.

7 - Scheduling
Workload - processes running in the system
Processes are sometimes called jobs.
Turnaround time - the time at which the job completes - the time at which the job arrived in the system.

FCFS: simple.
Can lead to convoy effect (a # of short consumers of a resource get queued behind a large consumer).

SJF - Shortest Job First. Not preemptive so if a long job arrives first, it will still go before shorter jobs and increase turnaround time.

STCF - Shortest Time-to-Completion First. Preemptive.

New metric - response time.
Response time = time from when the job arrives in a system to the first time its scheduled.

RR - Round Robin. Runs job for a time slice and then switches to the next job in the run queue. Can't keep the time slice too small because context switching is expensive. So there's a tradeoff with getting better response time and context switching with lower time slices. RR is bad for turnaround time but good for response time.

Good for turnaround time: SJF, STCF
Good for response time: RR

During I/O, process another job to avoid wasting CPU time.

8 - Multi-Level Feedback Queue (MLFQ)
1. Optimizes turnaround time
2. Minimize response time

MLFQ has multiple distinct queues that all have a different priority level. MLFQ uses priorities to decide which job should run at a given time. Job on a higher queue will be chosen to run. Jobs on the same queue have the same priority. Those will have round robin scheduling.

MLFQ varies priority based on observed behavior. If a job relinquishes the CPU while waiting for input from the keyboard, MLFQ would keep the priority high, as this is how a interactive process would behave. If a job uses the CPU for long periods of time, it will have lower priority.

Allotment - amount of time a job can spend at a given priority level before the scheduler reduces its priority.

If a job is short, it will finish quickly. If not, it will move down queues to lower priority.

If a job does a lot of I/O, we don't penalize it because it voluntary gives up CPU time.

Starvation - long running jobs can starve behind short, interactive jobs
Gaming the scheduler - relinquish CPU, remaining in the same queue strategically.

Priority boost - periodically boost the priority of all jobs in the system.

Every s seconds, all jobs are moved to the topmost (highest priority) queue.

To prevent gaming, the scheduler can keep track of the the allotment for each process instead of forgetting it. After the allotment is used, the process is demoted to the next priority queue.

Higher priority queues are usually given shorter time slices since they are usually composed of interactive jobs. Lower priority queues get longer time slices. This is because they are more CPU intensive.

General MLFQ Rules:
1. If Priority(A) > P(B), A runs
2. If P(B) = P(A), Round robin A and Batch
3. Jobs enter system at highest priority queue
4. Once job uses up allotment at a given level its moved down one queue
5. After some time period s, move all jobs in the system to the topmost queue. (Priority evaluation, prevent starvation, adapt if jobs now have more I/O, prevent overloading lower priority queues).

9 - Scheduling Proportional shared

Proportional share scheduler (fair time scheduler) - instead of optimizing for response time or turnaround time, a scheduler might instead try to guarantee each job gets a certain percentage of CPU time.

Lottery scheduling - every now and then, a lottery is conducted to determine which process runs next. Processes that should run more often have a higher chance of winning the lottery.

Tickets - used to represent share of a resource

Randomness is good - lightweight, fast, and avoids worst case scenarios.

Ticket currency - lets a user with a set of tickets to allocate tickets among their own jobs in whatever currency. The system converts the currency into global value.

Ticket transfer - processes can hand of tickets to another process.

linked-list like data structure used to find the lottery winner. Keep track of a counter and traverse the list to find a winner.

Fairness metric - time the first job completes divided by the time the second job completes.
Fairness increases with job length.

Stride Scheduling: // stride value calculation?
Divide some large number by the number of tickets each process was assigned. This is the stride value. Every time a process runs, we will increment a counter (pass value) for it by its stride to track global progress.
Every iteration we choose the client with the min pass value.

Advantage of lottery scheduling over stride scheduling: no global state. If a new job enters a stride scheduler with pass 0, it will monopolize the CPU.

Linux Completely Fair Scheduler (CFS) - 
little time spent making scheduling decisions. Goal is to fairly divide a CPU evenly among all competing processes.

Virtual runtime - vruntime - as each process runs, it accumulates vruntime. Each processes vrtuntime increases at same rate. CFS picks process with lowest vruntime.

sched_latency - how long a process should run before considering a switch (dynamic time slice). Typically 48 ms. Divide sched latency by number of processes to determine time slice.

min_granularity - usually 6ms. CFS never sets time slice below this value, ensuring time slices aren't too short and overhead is minimized.

CFS has a periodic timer interrupt (every 1 ms) to determine if process reached end of its time slice. It approximates for non-perfect multiples.

nice parameter (-20 to 19, default = 0) - positive = lower priority and negative = higher priority. Users and admins can adjust nice values to give processes a higher or lower share of the CPU.

The nice value of each process mapped to a weight. Weights let us compute the time slice of each process. Accounting for priority differences.

Red-black tree - balanced tree. Holds runnable processes. If process requests I/O and sleeps, it is removed from the tree. Lets us search, insert, and delete at O(log n) time.

If a job sleeps for a while CFS sets the vruntime of that job to the min value in the tree to prevent monopolization.